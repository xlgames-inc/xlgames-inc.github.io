<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Home</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="XL Games">

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le styles -->
<link href='/assets/stylesheets/bootstrap.min-93b47f97c3444c4711853ed5140d82a1.css' type='text/css' rel='stylesheet' media='all'>
<link href='/assets/stylesheets/style-1dcb1d39791f3457afa56d279fcf0945.css' type='text/css' rel='stylesheet' media='all'>
<link href='/assets/stylesheets/google_prettify/sons-of-obsidian-5e05343fd0c18e0a05231023b643245c.css' type='text/css' rel='stylesheet' media='all'>
    <!-- Le fav and touch icons -->
  <!-- Update these with your own images
    <link rel="shortcut icon" href="images/favicon.ico">
    <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
  -->
  </head>

  <body>

    <div class="navbar">
      <div class="navbar-inner">
        <div class="container-narrow">
          <a class="brand" href="/">XLE development blog</a>
          <ul class="nav">
              
                <li><a href="/tags">Tags</a></li>
              
              
                <li><a href="/archive">Archive</a></li>
              
              
                <li><a href="/about">About</a></li>
              
          </ul>
        </div>
      </div>
    </div>

    <div class="container-narrow">

      <div class="content">
        <div class="page-header">
  <h1>Home </h1>
</div>

<div class="row-fluid">
  <div class="span12">
    <p>
    XLE is a open-source (MIT license) game engine currently in development at XL Games.<br />
    <i>Please note; this engine is still a work in progress!</i>
</p>
<p>For more information, see our <a href="https://github.com/xlgames-inc/XLE/wiki">wiki on Github</a></p>
<p>Dev team contact: <a href="mailto:xle@xlgames.com">xle@xlgames.com</a> (in English or Korean)</p>

  <h2>2016</h2>
    <h3>June</h3>
    <ul>
      <li><span>June 19, 2016</span> &raquo; <a href="/posts/juneupdate">Latest Update</a></li>
    </ul>
    <h3>May</h3>
    <ul>
      <li><span>May 09, 2016</span> &raquo; <a href="/posts/metallayerrefactoring">Vulkan prototype - metal layer refactoring</a></li>
      <li><span>May 04, 2016</span> &raquo; <a href="/posts/vulkanmoreprogress">Vulkan latest progress -- core lighting working</a></li>
    </ul>
    <h3>April</h3>
    <ul>
      <li><span>April 22, 2016</span> &raquo; <a href="/posts/vulkandeclarativelightingparser">Vulkan prototype - how many separate render passes in the lighting parser?</a></li>
      <li><span>April 15, 2016</span> &raquo; <a href="/posts/vulkanbigissues">Vulkan prototype - the big issues</a></li>
      <li><span>April 12, 2016</span> &raquo; <a href="/posts/vulkantips">Important Vulkan tips</a></li>
      <li><span>April 08, 2016</span> &raquo; <a href="/posts/vulkanprototypeslowprogress">Vulkan prototype slowly progressing</a></li>
      <li><span>April 05, 2016</span> &raquo; <a href="/posts/vulkanshaderprototype">HLSL shader prototype with Vulkan</a></li>
      <li><span>April 04, 2016</span> &raquo; <a href="/posts/vulkan">Starting to experiment with Vulkan</a></li>
    </ul>
    <h3>March</h3>
    <ul>
      <li><span>March 31, 2016</span> &raquo; <a href="/posts/compareoitrans">Comparing different methods for order independent transparency</a></li>
      <li><span>March 30, 2016</span> &raquo; <a href="/posts/envshots">Environment Rendering Screenshots</a></li>
      <li><span>March 26, 2016</span> &raquo; <a href="/posts/release0040">Release v0.04.0</a></li>
      <li><span>March 25, 2016</span> &raquo; <a href="/posts/environmentsample">Environment Sample Streamlining</a></li>
      <li><span>March 14, 2016</span> &raquo; <a href="/posts/newtoolfeatures">Latest Tool Features</a></li>
    </ul>
    <h3>February</h3>
    <ul>
      <li><span>February 05, 2016</span> &raquo; <a href="/posts/transmittedspecular3">Transmitted specular</a></li>
      <li><span>February 01, 2016</span> &raquo; <a href="/posts/improvedibl">Improved IBL</a></li>
    </ul>
    <h3>January</h3>
    <ul>
      <li><span>January 29, 2016</span> &raquo; <a href="/posts/transmittedspecular2">Transmitted specular progress</a></li>
      <li><span>January 26, 2016</span> &raquo; <a href="/posts/assetpathscripts">Processing textures with the XLE scriptable asset path</a></li>
      <li><span>January 25, 2016</span> &raquo; <a href="/posts/transmittedspecular">Transmitted specular</a></li>
      <li><span>January 22, 2016</span> &raquo; <a href="/posts/transmissionnodegraph">Transmission Node Diagram</a></li>
      <li><span>January 21, 2016</span> &raquo; <a href="/posts/materialtool">Material and Node Diagram Tool</a></li>
    </ul>
  <h2>2015</h2>
    <h3>December</h3>
    <ul>
      <li><span>December 16, 2015</span> &raquo; <a href="/posts/functionlinkedshaders">Dynamic Function Linking Graph for Shaders</a></li>
      <li><span>December 11, 2015</span> &raquo; <a href="/posts/rectlightdiffuse">Rectangle Light diffuse vs 3DS Max</a></li>
      <li><span>December 09, 2015</span> &raquo; <a href="/posts/workingonrectlights">Working some improvements to rectangle lights</a></li>
      <li><span>December 04, 2015</span> &raquo; <a href="/posts/whattodofirst">What to do first</a></li>
      <li><span>December 02, 2015</span> &raquo; <a href="/posts/arealightsandpbr">Area Lights with Physically Based Rendering</a></li>
      <li><span>December 01, 2015</span> &raquo; <a href="/posts/first">First post</a></li>
    </ul>

<p><img src="/assets/media/NyraAndDragon1.png"></p>
<p><img src="/assets/media/EnvShots/shot50.jpg"></p>
<p><a href="posts/envshots">More screenshots</a></p>

<hr />

<div class="post">
  <h3 class="title"><a href="/posts/juneupdate">Latest Update</a><br /> <span class="date">June 19, 2016</span></h3>

  <div class="summary ellipsis">
<p>Work is still continuing on XLE! Over the last few weeks, I've have been very distracted by other priorities. I'm likely to be somewhat busy and distracted during for a few more weeks until things return to a more normal situation.
However, I'm still finding time to work on XLE, and make some improvements and fixes!</p>

<p>Lately, my focus has been on <strong>Vulkan</strong> support (in the <em>experimental</em> branch). Vulkan is looking more and more stable and reliable, and the HLSL -&gt; SPIR-V path is working really well now!
However, there are still some big things I want to improve on:</p>

<ul>
<li>Improved interface for BoundUniforms, that can allow for precreation of descriptor sets during loading phases</li>
<li>Improved interface for Metal::ConstantBuffer and temporary vertex/index buffers that would rely on a single large circular device buffer</li>
<li>Pre-create graphics pipelines when using <code>SharedStateSet</code> (eg, when rendering <code>RenderCore::Assets::ModelRenderer</code>)

<ul>
<li><em>(this might also involve a better solution for the render state resolver objects used by materials)</em></li>
</ul>
</li>
<li>Fix triangle hit-test supported used by the tools (which is complicated by the render pass concept and requires stream output support)</li>
<li>Tessellation support for terrain rendering</li>
<li>Integration of MSAA resolve for Vulkan</li>
</ul>

<p>With these changes, we should start to see much more efficient results with the Vulkan pipeline. Some SceneEngine features won't work immediately, but otherwise we will be getting very good Vulkan results, while also retaining the DirectX compatibility! </p>

</div>

  <div class="more">
    <a href="/posts/juneupdate" class="btn btn-small">read more..</a>
  </div>
</div>
<div class="post">
  <h3 class="title"><a href="/posts/metallayerrefactoring">Vulkan prototype - metal layer refactoring</a><br /> <span class="date">May 09, 2016</span></h3>

  <div class="summary ellipsis">
<p>XLE has a thin layer over the underlying graphics API called "Metal". This was originally built for DirectX11 and OpenGLES. But over time it became more DirectX-focused. Part of the goal of building in Vulkan support was to provide a basis for refactoring and improving the metal layer.</p>

<p>The goals for this layer are simple:
- compile time polymorphism between underlying graphics APIs
 - not link time or run time. We know the target during compilation of client code
- "leaky" abstraction layer
 - meaning that most client code is independent of the underlying graphics API
 - but the underlying objects are still accessible, so client code can write API-specific code when needed
- very thin, minimal overhead
 - for example, many DeviceContext methods get inlined into client code, meaning that performance is similar to using the underlying API directly</p>

<p>To make this kind of layer work, we need to find abstractions that work well for all target APIs. Usually this means finding abstractions that are great for one API, and pretty good for other APIs. That can be tricky, particularly as APIs are changing and evolving over time.</p>

<h2 id="toc_0">Descriptor Set concept</h2>

<p>Ideally we want the concept of "descriptor sets" to exist in the metal API somewhere. There are two reasons for this:</p>

<ol>
<li>Clean up the DeviceContext interface so there are fewer BindXX(...) methods</li>
<li>pre-cook permanent descriptor sets using BoundUniforms (or otherwise), so that they can be reused frame to frame</li>
</ol>

</div>

  <div class="more">
    <a href="/posts/metallayerrefactoring" class="btn btn-small">read more..</a>
  </div>
</div>
<div class="post">
  <h3 class="title"><a href="/posts/vulkanmoreprogress">Vulkan latest progress -- core lighting working</a><br /> <span class="date">May 04, 2016</span></h3>

  <div class="summary ellipsis">
<p>The Vulkan build is steadily getting more and more functionality. Now the core rendering pipeline in SceneEngine is working -- which means we can have deferred lighting, shadows, IBL, tonemapping, etc. Simple scene should render correctly now. But there are some inefficiencies and issues (see below).</p>

<p>Unfortunately the DirectX11 version isn't working at the moment. This is all in the "experimental" branch.</p>

<h2 id="toc_0">Declarative render passes</h2>

<p>Tone-mapping now works, and it was a good prototype for the "declarative" render pass model. This allows us to specify render passes and render targets required using a "description" structure. The system will do some caching and correlate request to resources, creating and binding as necessary.</p>

<p>There is some overhead with this design because it involves doing some per-frame hash and lookups as we go along. It's not as efficient as (for example) just pre-creating all of the frame buffer / render pass objects in a configure step. However, this design is maybe a little more flexible and easier to tie into existing scene engine code. In effect, we're building a new layer that is just one step more abstract from the underlying Vulkan objects.</p>

<p>I've pushed some of the "busy-work" (like declaring subpass dependencies) down into the RenderCore::Metal layer. This makes the interface easier to use... But the downside is that my abstraction is not expressive enough for some unusual cases. For example, I came across a cases where we want to bind the "depth &amp; stencil" aspects of a depth texture in one subpass; and in the second subpass only the "stencil" aspect is bound. This apparently needs a dependency... But it's just really inconvenient with this interface.</p>

<p>I've also build a concept called "named resources" into the Metal::DeviceContext. This allows us to get TextureViews for  attachments from the device context. It feels out of place because it's an operation that doesn't involve the hardware, but there doesn't seem to be any better way to handle this case.</p>

<p>Fundamentally we want to define attachments FrameBufferDesc objects, so that we can later refer to them again by binding id. It would be better if some of this functionality was in the RenderCore::Techniques library... But it would be just too much hassle to split it better Techniques and Metal.</p>

<p>Anyway, it's working now in Vulkan. However, I still haven't got to the caching and reuse part. And it also needs to be implemented for DirectX11, also!</p>

<h2 id="toc_1">Compute shader work!</h2>

<p>I added in support for the compute pipeline. It actually was pretty easy. I decided to switch some of the tonemapping code from pixel shaders to compute shaders -- because this seems to be more natural in Vulkan. Working with viewports and render targets is much more complex in Vulkan than DirectX11.</p>
</div>

  <div class="more">
    <a href="/posts/vulkanmoreprogress" class="btn btn-small">read more..</a>
  </div>
</div>
<div class="post">
  <h3 class="title"><a href="/posts/vulkandeclarativelightingparser">Vulkan prototype - how many separate render passes in the lighting parser?</a><br /> <span class="date">April 22, 2016</span></h3>

  <div class="summary ellipsis">
<p>The lighting parser is a set of steps (including geometry rendering and full screen passes) that occur in a similar order and configuration every frame. In some ways it is like a higher level version of a "renderpass" (or frame buffer layout). Each "subpass" in the renderpass is like a step in the lighting parser process for evaluating the frame.</p>

<p>But how do we map the lighting parser steps onto render pass subpasses? Do we want to use one single huge render pass for everything? Or a number of small passes?</p>

<h2 id="toc_0">Declarative lighting parser</h2>

<p>Since we're using a "declarative" approach for "frame buffer layouts", we could do the same for the lighting parser. Imagine a LightingParserConfiguration object that takes a few configuration variables (related to the current platform and quality mode, and also scene features) and produces the set of steps that the lighting parser will perform.</p>

<p>We could use the <code>VariantFunctions</code> interface for this, along with some structures to define the "attachment" inputs and outputs for each step. If we have a step (such as tonemapping) we just define the input attachments, output attachments, and temporary buffers required, and add the tone map function.</p>

<p>Then we would just need a small system that could collect all this information, and generate a <code>RenderCore::FrameBufferDesc</code> object from it.</p>

<p>This would allow us to have a very configurable pipeline, because we could just build up the list of steps as we need them, and from there generate everything we need. In effect, we would declare everything that is going to happen in the lighting parser before hand; and then the system would automatically calculate everything that needs to happen when we call Run().</p>

<p>This could also allow us to have a single render pass for the entire lighting parser process. But is that what we really want?</p>

<h2 id="toc_1">How many render passes?</h2>

<p>There are a few things to consider:</p>

<ol>
<li>Compute shader usage</li>
<li>frame-to-frame variations in the render pass</li>
<li>parallization within the lighting parser</li>
</ol>
</div>

  <div class="more">
    <a href="/posts/vulkandeclarativelightingparser" class="btn btn-small">read more..</a>
  </div>
</div>
<div class="post">
  <h3 class="title"><a href="/posts/vulkanbigissues">Vulkan prototype - the big issues</a><br /> <span class="date">April 15, 2016</span></h3>

  <div class="summary ellipsis">
<p>I'm making more progress on the <em>Vulkan</em> prototype. Now the SceneEngine compiles, BufferUploads works, and it's now possible to render basic geometry. Many features aren't supported. But the core rendering features (such as binding textures, compiling shaders, pushing geometry through the pipeline) have an early implementation.</p>

<p>So, while a working <em>Vulkan</em> version is now close, I have a much better idea of what major hurdles there would be to get a really streamlined and efficient <em>Vulkan</em> implementation!</p>

<h2 id="toc_0">RenderPasses</h2>

<p>This is going to be the big issue. RenderPasses are a new concept in <em>Vulkan</em> (though with heritage from <em>Apple Metal</em> and <em>OpenGL</em>), and not very compatible with the DirectX way of handling render targets. This is going to require some deep thought!</p>

<p>I haven't researched this thoroughly -- but this is my basic understanding of what might be happening...</p>

<p>RenderPasses seem to be fundamentally designed around PowerVR-style hardware (such as that found in IPhones and some Android hardware). Now, if I understand the situation correctly, this type of hardware doesn't need a traditional depth buffer. Instead it collates triangles as they are submitted, then splits them into buckets for tiles on the screen, and finally decomposes them into scanlines. The scanlines can be sorted using an old algorithm, so that for every pixel we know the front-most scanline.</p>

<p>The key issue here is that that we collate triangle information in the frame buffer, and do not produce a final pixel value until all triangles are finished. This requires the hardware to maintain buffers of triangle scanlines attached to the frame buffer.</p>

<p>The key problem here is this: what happens if we have render targets A and B, both of which are used in the same frame. We render to A, then to B, and then switch back to A and start rendering again?</p>

<p>In a traditional DirectX <code>OMSetRenderTargets</code> environment, this is not a big issue. We might do this (for example) to render a reflection into target B, which appears on geometry in target A. Maybe we cause a bit of a GPU pipeline stall; but it's probably not going to be a major issue.</p>

<p>With the PowerVR-style hardware, however, it's a bigger deal. We want to continue collating triangle information in A throughout the entire frame. We don't want to separate that into 2. It would be better if A and B were actually 2 separate viewports onto the same frame buffer.</p>

<p>In other words, when we switch away from A, we kind of want to know if we will be returning to it. That's what RenderPasses are useful for. We can express to the API that A is not finished yet, and that B just contains temporary data that will eventually be used on A.</p>
</div>

  <div class="more">
    <a href="/posts/vulkanbigissues" class="btn btn-small">read more..</a>
  </div>
</div>

<div class="pagination">
  <ul>
      <li class="active"><a href="/posts/index/1">1</a></li>
      <li><a href="/posts/index/2">2</a></li>
      <li><a href="/posts/index/3">3</a></li>
      <li><a href="/posts/index/4">4</a></li>
      <li><a href="/posts/index/5">5</a></li>
      <li><a href="/posts/index/6">6</a></li>
  </ul>
</div>

  </div>
</div>

      </div>

      <hr>
      <div class="footer">
        <p>&copy; XL Games 2015
          with help from <a href="http://ruhoh.com" target="_blank" title="The Definitive Technical Blogging Framework">ruhoh</a>
          and <a href="http://twitter.github.com/bootstrap/" target="_blank">Twitter Bootstrap</a>
        </p>
      </div>

    </div> <!-- /container -->

    <!-- Google Prettify -->
<script src="http://cdnjs.cloudflare.com/ajax/libs/prettify/188.0.0/prettify.js"></script>
<script>
  var pres = document.getElementsByTagName("pre");
  for (var i=0; i < pres.length; ++i) {
    pres[i].className = "prettyprint linenums";
  }
  prettyPrint();
</script>
<!-- end Google Prettify -->
    <script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-71034032-1']);
  _gaq.push(['_trackPageview']);
  

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>


    
  </body>
</html>
