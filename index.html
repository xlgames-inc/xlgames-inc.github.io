<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Home</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="XL Games">

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le styles -->
<link href='/assets/stylesheets/bootstrap.min-93b47f97c3444c4711853ed5140d82a1.css' type='text/css' rel='stylesheet' media='all'>
<link href='/assets/stylesheets/style-1dcb1d39791f3457afa56d279fcf0945.css' type='text/css' rel='stylesheet' media='all'>
<link href='/assets/stylesheets/google_prettify/sons-of-obsidian-5e05343fd0c18e0a05231023b643245c.css' type='text/css' rel='stylesheet' media='all'>
    <!-- Le fav and touch icons -->
  <!-- Update these with your own images
    <link rel="shortcut icon" href="images/favicon.ico">
    <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
  -->
  </head>

  <body>

    <div class="navbar">
      <div class="navbar-inner">
        <div class="container-narrow">
          <a class="brand" href="/">XLE development blog</a>
          <ul class="nav">
              
                <li><a href="/tags">Tags</a></li>
              
              
                <li><a href="/archive">Archive</a></li>
              
              
                <li><a href="/about">About</a></li>
              
          </ul>
        </div>
      </div>
    </div>

    <div class="container-narrow">

      <div class="content">
        <div class="page-header">
  <h1>Home </h1>
</div>

<div class="row-fluid">
  <div class="span12">
    <p>
    XLE is a open-source (MIT license) game engine currently in development at XL Games.<br />
    <i>Please note; this engine is still a work in progress!</i>
</p>
<p>For more information, see our <a href="https://github.com/xlgames-inc/XLE/wiki">wiki on Github</a></p>
<p>Dev team contact: <a href="mailto:xle@xlgames.com">xle@xlgames.com</a> (in English or Korean)</p>

  <h2>2016</h2>
    <h3>May</h3>
    <ul>
      <li><span>May 04, 2016</span> &raquo; <a href="/posts/vulkanmoreprogress">Vulkan latest progress -- core lighting working</a></li>
    </ul>
    <h3>April</h3>
    <ul>
      <li><span>April 22, 2016</span> &raquo; <a href="/posts/vulkandeclarativelightingparser">Vulkan prototype - how many separate render passes in the lighting parser?</a></li>
      <li><span>April 15, 2016</span> &raquo; <a href="/posts/vulkanbigissues">Vulkan prototype - the big issues</a></li>
      <li><span>April 12, 2016</span> &raquo; <a href="/posts/vulkantips">Important Vulkan tips</a></li>
      <li><span>April 08, 2016</span> &raquo; <a href="/posts/vulkanprototypeslowprogress">Vulkan prototype slowly progressing</a></li>
      <li><span>April 05, 2016</span> &raquo; <a href="/posts/vulkanshaderprototype">HLSL shader prototype with Vulkan</a></li>
      <li><span>April 04, 2016</span> &raquo; <a href="/posts/vulkan">Starting to experiment with Vulkan</a></li>
    </ul>
    <h3>March</h3>
    <ul>
      <li><span>March 31, 2016</span> &raquo; <a href="/posts/compareoitrans">Comparing different methods for order independent transparency</a></li>
      <li><span>March 30, 2016</span> &raquo; <a href="/posts/envshots">Environment Rendering Screenshots</a></li>
      <li><span>March 26, 2016</span> &raquo; <a href="/posts/release0040">Release v0.04.0</a></li>
      <li><span>March 25, 2016</span> &raquo; <a href="/posts/environmentsample">Environment Sample Streamlining</a></li>
      <li><span>March 14, 2016</span> &raquo; <a href="/posts/newtoolfeatures">Latest Tool Features</a></li>
    </ul>
    <h3>February</h3>
    <ul>
      <li><span>February 05, 2016</span> &raquo; <a href="/posts/transmittedspecular3">Transmitted specular</a></li>
      <li><span>February 01, 2016</span> &raquo; <a href="/posts/improvedibl">Improved IBL</a></li>
    </ul>
    <h3>January</h3>
    <ul>
      <li><span>January 29, 2016</span> &raquo; <a href="/posts/transmittedspecular2">Transmitted specular progress</a></li>
      <li><span>January 26, 2016</span> &raquo; <a href="/posts/assetpathscripts">Processing textures with the XLE scriptable asset path</a></li>
      <li><span>January 25, 2016</span> &raquo; <a href="/posts/transmittedspecular">Transmitted specular</a></li>
      <li><span>January 22, 2016</span> &raquo; <a href="/posts/transmissionnodegraph">Transmission Node Diagram</a></li>
      <li><span>January 21, 2016</span> &raquo; <a href="/posts/materialtool">Material and Node Diagram Tool</a></li>
    </ul>
  <h2>2015</h2>
    <h3>December</h3>
    <ul>
      <li><span>December 16, 2015</span> &raquo; <a href="/posts/functionlinkedshaders">Dynamic Function Linking Graph for Shaders</a></li>
      <li><span>December 11, 2015</span> &raquo; <a href="/posts/rectlightdiffuse">Rectangle Light diffuse vs 3DS Max</a></li>
      <li><span>December 09, 2015</span> &raquo; <a href="/posts/workingonrectlights">Working some improvements to rectangle lights</a></li>
      <li><span>December 04, 2015</span> &raquo; <a href="/posts/whattodofirst">What to do first</a></li>
      <li><span>December 02, 2015</span> &raquo; <a href="/posts/arealightsandpbr">Area Lights with Physically Based Rendering</a></li>
      <li><span>December 01, 2015</span> &raquo; <a href="/posts/first">First post</a></li>
    </ul>

<p><img src="/assets/media/NyraAndDragon1.png"></p>
<p><img src="/assets/media/EnvShots/shot50.jpg"></p>
<p><a href="posts/envshots">More screenshots</a></p>

<hr />

<div class="post">
  <h3 class="title"><a href="/posts/vulkanmoreprogress">Vulkan latest progress -- core lighting working</a><br /> <span class="date">May 04, 2016</span></h3>

  <div class="summary ellipsis">
<p>The Vulkan build is steadily getting more and more functionality. Now the core rendering pipeline in SceneEngine is working -- which means we can have deferred lighting, shadows, IBL, tonemapping, etc. Simple scene should render correctly now. But there are some inefficiencies and issues (see below).</p>

<p>Unfortunately the DirectX11 version isn't working at the moment. This is all in the "experimental" branch.</p>

<h2 id="toc_0">Declarative render passes</h2>

<p>Tone-mapping now works, and it was a good prototype for the "declarative" render pass model. This allows us to specify render passes and render targets required using a "description" structure. The system will do some caching and correlate request to resources, creating and binding as necessary.</p>

<p>There is some overhead with this design because it involves doing some per-frame hash and lookups as we go along. It's not as efficient as (for example) just pre-creating all of the frame buffer / render pass objects in a configure step. However, this design is maybe a little more flexible and easier to tie into existing scene engine code. In effect, we're building a new layer that is just one step more abstract from the underlying Vulkan objects.</p>

<p>I've pushed some of the "busy-work" (like declaring subpass dependencies) down into the RenderCore::Metal layer. This makes the interface easier to use... But the downside is that my abstraction is not expressive enough for some unusual cases. For example, I came across a cases where we want to bind the "depth &amp; stencil" aspects of a depth texture in one subpass; and in the second subpass only the "stencil" aspect is bound. This apparently needs a dependency... But it's just really inconvenient with this interface.</p>

<p>I've also build a concept called "named resources" into the Metal::DeviceContext. This allows us to get TextureViews for  attachments from the device context. It feels out of place because it's an operation that doesn't involve the hardware, but there doesn't seem to be any better way to handle this case.</p>

<p>Fundamentally we want to define attachments FrameBufferDesc objects, so that we can later refer to them again by binding id. It would be better if some of this functionality was in the RenderCore::Techniques library... But it would be just too much hassle to split it better Techniques and Metal.</p>

<p>Anyway, it's working now in Vulkan. However, I still haven't got to the caching and reuse part. And it also needs to be implemented for DirectX11, also!</p>

<h2 id="toc_1">Compute shader work!</h2>

<p>I added in support for the compute pipeline. It actually was pretty easy. I decided to switch some of the tonemapping code from pixel shaders to compute shaders -- because this seems to be more natural in Vulkan. Working with viewports and render targets is much more complex in Vulkan than DirectX11.</p>
</div>

  <div class="more">
    <a href="/posts/vulkanmoreprogress" class="btn btn-small">read more..</a>
  </div>
</div>
<div class="post">
  <h3 class="title"><a href="/posts/vulkandeclarativelightingparser">Vulkan prototype - how many separate render passes in the lighting parser?</a><br /> <span class="date">April 22, 2016</span></h3>

  <div class="summary ellipsis">
<p>The lighting parser is a set of steps (including geometry rendering and full screen passes) that occur in a similar order and configuration every frame. In some ways it is like a higher level version of a "renderpass" (or frame buffer layout). Each "subpass" in the renderpass is like a step in the lighting parser process for evaluating the frame.</p>

<p>But how do we map the lighting parser steps onto render pass subpasses? Do we want to use one single huge render pass for everything? Or a number of small passes?</p>

<h2 id="toc_0">Declarative lighting parser</h2>

<p>Since we're using a "declarative" approach for "frame buffer layouts", we could do the same for the lighting parser. Imagine a LightingParserConfiguration object that takes a few configuration variables (related to the current platform and quality mode, and also scene features) and produces the set of steps that the lighting parser will perform.</p>

<p>We could use the <code>VariantFunctions</code> interface for this, along with some structures to define the "attachment" inputs and outputs for each step. If we have a step (such as tonemapping) we just define the input attachments, output attachments, and temporary buffers required, and add the tone map function.</p>

<p>Then we would just need a small system that could collect all this information, and generate a <code>RenderCore::FrameBufferDesc</code> object from it.</p>

<p>This would allow us to have a very configurable pipeline, because we could just build up the list of steps as we need them, and from there generate everything we need. In effect, we would declare everything that is going to happen in the lighting parser before hand; and then the system would automatically calculate everything that needs to happen when we call Run().</p>

<p>This could also allow us to have a single render pass for the entire lighting parser process. But is that what we really want?</p>

<h2 id="toc_1">How many render passes?</h2>

<p>There are a few things to consider:</p>

<ol>
<li>Compute shader usage</li>
<li>frame-to-frame variations in the render pass</li>
<li>parallization within the lighting parser</li>
</ol>
</div>

  <div class="more">
    <a href="/posts/vulkandeclarativelightingparser" class="btn btn-small">read more..</a>
  </div>
</div>
<div class="post">
  <h3 class="title"><a href="/posts/vulkanbigissues">Vulkan prototype - the big issues</a><br /> <span class="date">April 15, 2016</span></h3>

  <div class="summary ellipsis">
<p>I'm making more progress on the <em>Vulkan</em> prototype. Now the SceneEngine compiles, BufferUploads works, and it's now possible to render basic geometry. Many features aren't supported. But the core rendering features (such as binding textures, compiling shaders, pushing geometry through the pipeline) have an early implementation.</p>

<p>So, while a working <em>Vulkan</em> version is now close, I have a much better idea of what major hurdles there would be to get a really streamlined and efficient <em>Vulkan</em> implementation!</p>

<h2 id="toc_0">RenderPasses</h2>

<p>This is going to be the big issue. RenderPasses are a new concept in <em>Vulkan</em> (though with heritage from <em>Apple Metal</em> and <em>OpenGL</em>), and not very compatible with the DirectX way of handling render targets. This is going to require some deep thought!</p>

<p>I haven't researched this thoroughly -- but this is my basic understanding of what might be happening...</p>

<p>RenderPasses seem to be fundamentally designed around PowerVR-style hardware (such as that found in IPhones and some Android hardware). Now, if I understand the situation correctly, this type of hardware doesn't need a traditional depth buffer. Instead it collates triangles as they are submitted, then splits them into buckets for tiles on the screen, and finally decomposes them into scanlines. The scanlines can be sorted using an old algorithm, so that for every pixel we know the front-most scanline.</p>

<p>The key issue here is that that we collate triangle information in the frame buffer, and do not produce a final pixel value until all triangles are finished. This requires the hardware to maintain buffers of triangle scanlines attached to the frame buffer.</p>

<p>The key problem here is this: what happens if we have render targets A and B, both of which are used in the same frame. We render to A, then to B, and then switch back to A and start rendering again?</p>

<p>In a traditional DirectX <code>OMSetRenderTargets</code> environment, this is not a big issue. We might do this (for example) to render a reflection into target B, which appears on geometry in target A. Maybe we cause a bit of a GPU pipeline stall; but it's probably not going to be a major issue.</p>

<p>With the PowerVR-style hardware, however, it's a bigger deal. We want to continue collating triangle information in A throughout the entire frame. We don't want to separate that into 2. It would be better if A and B were actually 2 separate viewports onto the same frame buffer.</p>

<p>In other words, when we switch away from A, we kind of want to know if we will be returning to it. That's what RenderPasses are useful for. We can express to the API that A is not finished yet, and that B just contains temporary data that will eventually be used on A.</p>
</div>

  <div class="more">
    <a href="/posts/vulkanbigissues" class="btn btn-small">read more..</a>
  </div>
</div>
<div class="post">
  <h3 class="title"><a href="/posts/vulkantips">Important Vulkan tips</a><br /> <span class="date">April 12, 2016</span></h3>

  <div class="summary ellipsis">
<p>After 1 week of playing around with Vulkan, here are 4 tips I've learned. These are maybe not very obvious (some aren't clearly documented), but I think they're important to know.</p>

<h2 id="toc_0">1. Use buffers as staging areas to initialize images</h2>

<p>The crux of this is we need to use a function, <em>vkCmdCopyBufferToImage</em>, to implement staging images with Vulkan. It's almost impossible to do any graphics work with Vulkan without doing this -- but a first glance it might seem a bit counter-intuitive. First a bit of a background.</p>

<p>Vulkan images have a "tiling" property, which can be either "linear" or "optimal." This is property relates to how pixels are arranged in memory within a single mip level.</p>

<p>In linear tiling, texels are arranged in row by row, column by column. So a texel's linear address follows this pattern:</p>

<pre><code>address = (y*rowPitch) + x*bitsPerPixel/8
</code></pre>

<p>When we have images on disk, we usually expect them to have this tiling.</p>

<p>However, this has a big problem. Texels in the same row will be near each other in memory. But texels in the same column will be quite separate in memory.</p>

<p>Given that images can be mapped arbitrarily on the final 2D triangles, we can't control the order in which the GPU will access the texels. So this is big issue for the memory cache.</p>

<p>So all GPUs are able to rearrange the texels into a "swizzled" order that tries to guarantee that nearby texels in 2D (or 3D) image space will be nearby in linear memory. This is called "optimal" tiling in Vulkan.</p>

</div>

  <div class="more">
    <a href="/posts/vulkantips" class="btn btn-small">read more..</a>
  </div>
</div>
<div class="post">
  <h3 class="title"><a href="/posts/vulkanprototypeslowprogress">Vulkan prototype slowly progressing</a><br /> <span class="date">April 08, 2016</span></h3>

  <div class="summary ellipsis">
<p>So, the Vulkan prototype is progress... But I'm running into many problems working with the drivers and the associated tools. Here's some examples of the problems I'm finding.</p>

<h2 id="toc_0">RenderDoc crashing</h2>

<p>RenderDoc is the best tool for debugging Vulkan at the moment... But every time I tried to capture a log, it just crashed! The crash report didn't contain any useful information. All I could do was guess at the problem.</p>

<p>Fortunately, RenderDoc has one really great feature... It's open-source! So, I just downloaded the code and ran from Visual Studio (it compiled first time).</p>

<p>RenderDoc is still very unstable for Vulkan. But now that I have my own compiled version, that's not really a big issue. I can just debug any crashes and make changes as required. All of the other GPU debugging tools I've ever used (PIX, console tools, GPA, nsight, etc) have been unstable, as well. But they were all closed source. So whenever I got an error, my only choices were to either use another debugging, or guess at the problem. With this in mind, (open-source + very unstable) is probably better than (closed-source + mostly stable).</p>

<p>My issue was related to "binding" decorations in SPIR-V. RenderDoc requires that all resources have binding decorations. I found this was also an issue for run-time XLE code. Even though the GLSL compiler is capable of generating SPIR-V code without binding decorations, it seems like all practical uses require them.</p>

<p>My shaders weren't getting "bindings" for any resources, and this was the cause of RenderDoc's crashes!</p>

<h2 id="toc_1">HLSL cross compiler and "bindings"</h2>

<p>Part of the issue is related to the HLSL cross compiler. In some cases, the cross compiler can attach "location" values, but it never attaches "binding" values for textures or constant buffers.</p>

<p>Fortunately, the HLSL cross compiler is also open-source... So I can create a fork with the modifications I need. That seems to be required in this case. I could try to attach the binding information later in the pipeline (eg, by modifying the output GLSL, or by inserting instructions into the SPIR-V bytecode)... But changing and improving the cross compiler seems like the best option.</p>

<p>We ideally also want to specify the "descriptor set" in the GLSL code. Unfortunately, HLSL 5 doesn't have an equivalent concept. That is going to require some more effort.</p>
</div>

  <div class="more">
    <a href="/posts/vulkanprototypeslowprogress" class="btn btn-small">read more..</a>
  </div>
</div>

<div class="pagination">
  <ul>
      <li class="active"><a href="/posts/index/1">1</a></li>
      <li><a href="/posts/index/2">2</a></li>
      <li><a href="/posts/index/3">3</a></li>
      <li><a href="/posts/index/4">4</a></li>
      <li><a href="/posts/index/5">5</a></li>
  </ul>
</div>

  </div>
</div>

      </div>

      <hr>
      <div class="footer">
        <p>&copy; XL Games 2015
          with help from <a href="http://ruhoh.com" target="_blank" title="The Definitive Technical Blogging Framework">ruhoh</a>
          and <a href="http://twitter.github.com/bootstrap/" target="_blank">Twitter Bootstrap</a>
        </p>
      </div>

    </div> <!-- /container -->

    <!-- Google Prettify -->
<script src="http://cdnjs.cloudflare.com/ajax/libs/prettify/188.0.0/prettify.js"></script>
<script>
  var pres = document.getElementsByTagName("pre");
  for (var i=0; i < pres.length; ++i) {
    pres[i].className = "prettyprint linenums";
  }
  prettyPrint();
</script>
<!-- end Google Prettify -->
    <script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-71034032-1']);
  _gaq.push(['_trackPageview']);
  

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>


    
  </body>
</html>
